import os
import torch
import argparse
import h5py
import numpy as np
import xgboost as xgb
import joblib
from models import PartialDeepSeaModel
os.environ["CUDA_VISIBLE_DEVICES"] = "0"
os.environ['CUDA_LAUNCH_BLOCKING'] = '1'


def predict_prob(data):
    knn_val_pred = knn_model.predict_proba(data)[:, 1]
    xgb_val_pred = xgb_model.predict(xgb.DMatrix(data))
    lgb_val_pred = lgb_model.predict(data)

    # 模型融合层
    stacking_X = np.vstack([knn_val_pred, xgb_val_pred, lgb_val_pred]).T
    rf_val_pred = rf_model.predict_proba(stacking_X)[:, 1]

    return rf_val_pred

def get_args():
    parser = argparse.ArgumentParser('Perform prediction using data generated by data_preparation.py')
    parser.add_argument('-m', '--model_file', type=str, required=True, help='The model prefix')
    parser.add_argument('--data_name', required=True, help='The data name.Like gm12878_ctcf')
    parser.add_argument('--data_file', required=True, help='The data file')
    parser.add_argument('--output_pre', required=True, help='The output file prefix')
    parser.add_argument('-p', '--all_predict', type=bool, default=False, help='Use all data for prediction.')
    args = parser.parse_args()
    return args


def load_factor_outputs(fn, all_predict):
    f = h5py.File(fn, 'r')
    left_out = f['left_out'][:]
    right_out = f['right_out'][:]
    dists = f['dists'][:]
    kmers = f['kmers'][:]
    if 'pairs' in f:
        pairs = f['pairs'][:]
    else:
        pairs = None
    data = np.concatenate((left_out, right_out, dists, kmers), axis=1)
    if not all_predict:
        labels = f['labels'][:]
        return data, labels, pairs
    else:
        return data, pairs


if __name__ == '__main__':
    # with torch.cuda.device(2):
    args = get_args()
    # 导入训练的模型
    model = PartialDeepSeaModel(4, use_weightsum=True, leaky=True)
    model.load_state_dict(torch.load(args.model_file))
    model.cuda()
    model.eval()
    # 导入分类器
    data_name = args.data_name
    knn_model = joblib.load('out_dir/' + data_name + '_knn_predictor.pkl')
    xgb_model = joblib.load('out_dir/' + data_name + '_xgb_predictor.pkl')
    lgb_model = joblib.load('out_dir/' + data_name + '_lgb_predictor.pkl')
    rf_model = joblib.load('out_dir/' + data_name + '_rf_predictor.pkl')
    # 导入扩展数据集的测试集
    if not args.all_predict:
        train_data, train_labels, train_pairs = load_factor_outputs(args.data_file, args.all_predict)
    else:
        train_data, train_pairs = load_factor_outputs(args.data_file, args.all_predict)
    probs = np.zeros(len(train_data))

    i = 0
    last_print = 0
    torch.cuda.empty_cache()

    # 用特征提取器提取特征
    while i < len(train_data) - 1:
        if i + 500 < len(train_data) - 1:
            end = i + 500
        else:
            end = len(train_data) - 1
        input_for_classifier = train_data[i:end]

        clf_preds = predict_prob(input_for_classifier)
        probs[i:end] = clf_preds

        if end - last_print > 5000:
            last_print = end
            print(
                'Predicted : %d / %d. With %d >= 0.5 so far' % (end, len(train_data), sum(probs[:end] >= 0.5)))
        i = end
    if hasattr(torch.cuda, 'empty_cache'):
        torch.cuda.empty_cache()


    with open(args.output_pre + '_FusNet_probs.txt', 'w') as out:
        # 增加了一个train_labels
        if not args.all_predict:
            for pair, prob, label in zip(train_pairs, probs, train_labels):
                pair_str = [str(p) for p in pair] + [str(prob)] + [str(label)]
                for i in [0, 3]:
                    if pair_str[i] == '23':
                        pair_str[i] = 'chrX'
                    else:
                        pair_str[i] = 'chr' + pair_str[i]
                out.write('\t'.join(pair_str) + '\n')
        else:
            for pair, prob in zip(train_pairs, probs):
                pair_str = [str(p) for p in pair] + [str(prob)]
                for i in [0, 3]:
                    if pair_str[i] == '23':
                        pair_str[i] = 'chrX'
                    else:
                        pair_str[i] = 'chr' + pair_str[i]
                out.write('\t'.join(pair_str) + '\n')
